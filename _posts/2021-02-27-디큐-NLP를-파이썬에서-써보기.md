---
layout: post
title:  "디큐 NLP를 파이썬에서 써보기"
date:  2021-02-27 15:17:44 +0900
categories: NLP
# keywords: "deeq NLP" python grpc baikalai 바이칼AI
author: 윤기현 <gih2yun@baikal.ai>
---
#### 새로운 시작

드디어 바이칼에이아이 기술 블로그를 시작합니다.
마음 맞는 사람들끼리 시작한 걸음이었습니다.
여러 사람들에게 도움이 되는 글쓰기를 지속적으로 해보자고 뜻을 모았습니다.
우리가 의미있는 기술 중심의 회사로 서 가는 과정을 기록하고 그려내는 글쓰기를 하려고 합니다.
회사의 성장에 대한 기록이겠지만, 글을 읽는 사람들에게도 최소한의 도움을 줄 수 있기를 기대합니다.

#### 디큐 NLP는
막상 새로운 기술과 제품을 선보인다는 것은 쉽지 않은 일입니다.
누군가에게 의미 있게 활용될 수 있는 물건을 만든다는 것 또한 인생을 걸고 해볼만한 즐거운 일입니다.
수많은 의미있는 일이 있겠지만, 자연어 처리 엔진을 가진다는 것은 매우 설레는 일입니다.

수많은 거인들의 어깨 위에서 그냥 빼꼼히 한뼘 정도의 높이를 더하는 수준이겠지만,
그래도 들인 노력이 의미있게 쓰일 수 있기를 기대해봅니다.

상용 수준의 NLP를 만드는 과정에서 다뤄볼 만한 많은 주제들은 차츰 꺼내기로 하겠습니다.
일단 오늘은 "디큐엔엘피"라는 새로운 제품을 사용하는 방법을 소개하려고 합니다. "deeq NLP"라고 씁니다.

## 시작하기

이 글은 인문과학이나 사회과학을 전공하는 대학 학부생 또는 고등학교 학생 수준에서
자연어 처리 엔진을 처음 접하는 사람들이
따라할 수 있는 수준에서 설명을 해볼까 합니다.
최소한 파이썬을 설치해보고 만져봤다면 시작할 수 있습니다.

### 설치하기

#### 가상환경 만들기

글쓴이가 윈도우즈를 안쓴지 20년이 넘어가서 모두 다 터미널 위주로 설명을 해야 합니다.
윈도우즈에서 리눅스를 설치해서 터미널을 사용하는 방법에 대해서는 [44bits.io][wsl2-install]의 글을 참조하면 좋겠습니다.

늘 그렇듯이 파이썬에서는 새로운 가상환경을 만들어서 작업을 해봐야죠!
늘 그렇듯이 가상환경은 빈 작업 폴더를 만들어서 작업하는 것이 좋습니다.
```shell
# mydeeq라는 폴더 만들기
mkdir mydeeq
# 폴더로 이동하기
cd mydeeq
# 새로운 deeqnlpy-test라는 파이썬 가상환경을 만듭니다.
# deeqnlpy-test라는 폴더를 만들고 새로운 파이썬 환경을 꾸밉니다.
python3 -m venv deeqnlpy-test
# 새 가상환경 deeqnlpy-test를 실행합니다.
source deeqnlpy-test/bin/activate
```
바로 위 명령줄에서 `source` 대신에 `.`을 쓰셔도 됩니다. 뒤에 온 파일을 불러들여서 실행하고 그 결과를 현재 상태에 반영하는 방법입니다.

아마도 프롬프트가 바뀌어 있을 것입니다. 쉘 설정에 따라 다양하겠지만 대략 다음과 같습니다.
```
(deeqnlpy-test) ➜  mydeeq _   # 여기에 보이는 _ 는 프롬프트입니다.
```

#### PIP 최신 버전으로 업그레이드하기

늘 그렇듯이 pip는 최신으로 업데이트 해주는 게 좋습니다.
pip는 파이썬용 패키지를 설치하는 도구입니다. 아래 명령을 사용하변 됩니다.

```shell
pip3 install --upgrade pip
```

아래와 비슷한 결과물들이 보일 것입니다.
각 환경마다 차이가 있을 수 있습니다.

```
Collecting pip
  Using cached pip-21.0.1-py3-none-any.whl (1.5 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 20.2.3
    Uninstalling pip-20.2.3:
      Successfully uninstalled pip-20.2.3
Successfully installed pip-21.0.1
```

#### 설치하기

마지막 단계입니다.

먼저 명령줄에서 간단하게 `deeqnlpy`라는 패키지를 설치하는 것으로 모든 것이 준비가 끝납니다.

```shell
(deeqnlpy-test) $ pip install deeqnlpy
```

위 명령을 실행하면, deeqnlpy 뿐 아니라 `grpcio`, `protobuf`, `six` 와 같은 추가적인 패키지들이 자동으로 설치됩니다.

```
Collecting deeqnlpy
  Downloading deeqnlpy-0.9.2-py3-none-any.whl (24 kB)
Collecting protobuf==3.14.0
  Using cached protobuf-3.14.0-py2.py3-none-any.whl (173 kB)
Collecting grpcio==1.35.0
  Using cached grpcio-1.35.0-cp39-cp39-macosx_10_10_x86_64.whl (3.8 MB)
Collecting six>=1.5.2
  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)
Installing collected packages: six, protobuf, grpcio, deeqnlpy
Successfully installed deeqnlpy-0.9.2 grpcio-1.35.0 protobuf-3.14.0 six-1.15.0```
```

### 뭐하는 녀석이지?

파이썬에서 새로운 녀석을 접할 때에는 `help` 하는 강략한 도구도 있습니다.
더 쉬운 도구는 `. <TAB>`을 이용해서 자동완성을 시키는 방법입니다. 이제 그 도구를 이용해서 안쪽을 파보도록 하죠.


다운로드를 마쳤으면 이제 콘솔을 통해서 새로 설치한 `deeqnlpy`를 사용해 보겠습니다.

먼저 터미널에서 python3 명령어를 칩니다.
다음에 `import deeqnlpy` 문장으로 패키지를 가져옵니다. `help(deeqnlpy)`를 입력하면 도움알믈 보실 수 있습니다.

```
(deeqnlpy-test) $ python3
Python 3.9.1 (default, Dec 10 2020, 11:11:14)
[Clang 12.0.0 (clang-1200.0.32.27)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> import deeqnlpy
>>> help(deeqnlpy)
```


#### help() 함수를 이용해서 도움말 보기

그러면 아래와 같은 메시지를 보실 수 있습니다.

```
Help on package deeqnlpy:

NAME
    deeqnlpy

DESCRIPTION
    DeeqNLPy
    =====
    Provides
      1. a Korean Part-Of-Speech Tagger as deeq NLP client
      2. Multiple custom dictionaries which is kept in the your deeq NLP server.


    How to use the documentation
    ----------------------------
    Full documentation for deeq NLP is available in
    installable tarball or docker images.
    - see `docs/intro.html` at installable tarball.
    - or `http://localhost:5757/intro.html` after running docker.
    
    The docstring examples assume that `deeqnlpy` has been imported as `dn`::
      >>> import deeqnlpy as dn
    
    Use the built-in ``help`` function to view a class's docstring::
      >>> help(dn.Tagger)

    Classes
    -------
    Tagger
        the deeq NLP POS tagger for Korean
        `from deeqnlpy import Tagger`
    Tagged
        Wrapper for tagged output
        `from deeqnlpy import Tagged`
    CustomDict
        Custom dictionary for Korean.
        `from deeqnlpy import CustomDict`
    Tagger
        the deeq NLP POS tagger for Korean
        `from deeqnlpy import Tagger`
    CustomDict
        Custom dictionary for Korean.
        `from deeqnlpy import CustomDict`
    DeeqTaggerCall
        Wrapper for single tagging function.
        `from deeqnlpy import DeeqTaggerCall`
    DeeqNlp
        Most available library.
        `from deeqnlpy import DeeqNlp`

    Version
    -------
    ```
    import deeqnlpy as dn
    print(dn.version)
    ```
    ## 이하 생략
```

다른 도움말을 얻어 볼 수도 있습니다.

```python
>>> help(deeqnlpy.Tagger)
>>> help(deeqnlpy.Tagged)
>>> help(deeqnlpy.CustomDict)
```

#### `<TAB>`을 이용해서 구조 파악해보기

프로그래밍 또는 개발은 무릇 공간지각능력이 많이 필요한 분야입니다.
마치 새로운 전자기기나 물건을 볼 때, 요리조리 조심스레 뜯어보게 됩니다. 만저보기도 하고, 두드리기도 하면서 말입니다.

파이썬에서 새로운 몰건을 요리조리 뜯어볼 때 쓰는 톡톡 건드릴 때는 '.'을 찍고 `<TAB>`을 쳐주면 됩니다.

 `<TAB>`으로 `deeqnlpy`의 구조를 한눈에 볼 수 있습니다.

```
>>> deeqnlpy.<TAB>
```
탭키를 누르면, 아래와 같은 결과물을 나옵니다.

```
>>> deeqnlpy.<TAB>
deeqnlpy.CustomDict(                     deeqnlpy.Tagged(                         deeqnlpy.os
deeqnlpy.CustomDictionaryServiceClient(  deeqnlpy.Tagger(                         deeqnlpy.sys
deeqnlpy.DeeqLanguageServiceClient(      deeqnlpy.deeq_nlp_version                deeqnlpy.version
```

여기에서 2가지 서로 다른 모습을 볼 수 있습니다. 
먼저 `deeqnlpy`는 불러들인(import) 패키지의 이름입니다.
이중에서 '(', 즉 여는 괄호가 있는 것들은 클래스나 함수입니다.
여는 괄호가 없는 것들은 상수이거나 다른 서브 패키지 입니다.

여기서 `deeq_nlp_version` 을 입력해보면, `1.4.2`를 출력하고 끝납니다.

```
>>> deeqnlpy.deeq_nlp_version
'1.4.2'
```
> 눈치채셨을지 모르지만, `deeqnlpy.version`과 `deeqnlpy.deeq_nlp_version`은 서로 다릅니다.
> `deeqnlpy.version`은 이 파이썬 패키지의 버전입니다. `deeq_nlp_version`은 이 파이썬 패키지와 연결되어 있는 
> 디큐 NLP의 버전입니다. 이 파이썬 패키지는 디큐 NLP를 사용하는 클라이언트 라이브러리입니다.
> 이 라이브러리는 반드시 서버에 연결해서 응답을 얻어오게 됩니다. 이 서버는 `nlp.deeq.ai` 라는 주소에 늘 존재하고 있습니다.
> 누구나 쓸 수 있습니다. 대신 직접 윈도우즈 PC에 설치할 수도 있습니다. 이것에 대해서는 다시 설명하겠습니다.


다른 도움말을 볼까요?

```
>>> deeqnlpy.Tagger.<TAB>
```
이번에는 또 다른 새로운 함수들이 나오는데, `Tagger` 클래스의 함수들이 잔뜩 나타납니다.

```
>>> deeqnlpy.Tagger.
deeqnlpy.Tagger.custom_dict(  deeqnlpy.Tagger.pos(
deeqnlpy.Tagger.domain        deeqnlpy.Tagger.post
deeqnlpy.Tagger.host          deeqnlpy.Tagger.set_domain(
deeqnlpy.Tagger.morphs(       deeqnlpy.Tagger.tag(
deeqnlpy.Tagger.mro(          deeqnlpy.Tagger.tags(
deeqnlpy.Tagger.nouns(        deeqnlpy.Tagger.verbs(
```

이중에서 `tags` 함수에 대한 도움말을 얻고 싶으시다면, `help()` 명령을 이용해서 결과를 얻을 수 있습니다.

```
>>> help(deeqnlpy.Tagger.tags)
Help on function tags in module deeqnlpy._tagger:

tags(self, phrase: [<class 'str'>]) -> deeqnlpy._tagger.Tagged
    tag string array.
    :param phrase: array of string
    :return: Tagged result instance
```


### 쓰임새 알아보기

`deeqnlpy`는 한국어 형태소를 분석해줍니다.
내부적으로는 디큐 NLP의 서버에 접속하여 형태소 분석을 요청하고 그 결과를 받아오는 방식입니다.

#### 실제로 분석해보기

`Tagger` 클래스가 그런 역할을 수행합니다. 여러가지 메소드들이 있는데, 그 쓰임새가 조금씩 다릅니다.

* tag: 문장 또는 여러 문장을 분석한 결과를 줍니다.
* tags: 여러 문장, 즉 문장의 배열을 분석하고 결과를 줍니다. 이 함수를 쓰는 걸 권장합니다.
* pos: 형태소 분석 결과 옵니다. 여러 문장일 때, 조금 곤란한 결과를 가져올 수 있습니다.
* morphs: 형태소만 꺼내옵니다.
* nouns: 명사류만 꺼내옵니다. 고유명사, 일반명사, 대명사까지 꺼내옵니다.
* verbs: 동사만 꺼내옵니다.

자 그럼 실제로 실행을 해볼까요?

```python
from deeqnlpy import Tagger
t = Tagger()
pos_tuples = t.pos("그 가수는 무리뉸데.")
print(pos_tuples)
```

실행을 해보면 다음과 같은 결과물을 얻을 수 있습니다.

```
[('그', 'MMD'), ('가수', 'NNG'), ('는', 'JX'), ('밍기뉴', 'NNP'), ('이', 'VCP'), ('ㄴ데', 'EF'), ('.', 'SF')]
```

여기에 사용한 어절은 모두 3개입니다. 
```
['그', '가수는', '밍기뉸데.']
```

#### 실재로 분석해보기(II)

`pos()` 함수의 결과물은 그런 구분없이 수평적으로 형태 분석한 결과물을 보여주고 있습니다.

이것을 어절 단위로 묶어서 결과를 가져올 수도 있습니다.

여기에서 `help(t.pos)`를 이용해서 도움말을 볼까요?
```
Help on method pos in module deeqnlpy._tagger:

pos(phrase: str, flatten: bool = True, join: bool  = False, full: bool = False) -> [] method of deeqnlpy._tagger.Tagger instance
    POS tagger.
    :param phrase  : string to analyse
    :param flatten : If False, returns original morphs.
    :param join    : If True, returns joined sets of morph and tag.
    :param full    : if True, returns every things of morph result
```

`pos()` 함수는 크게 4가지 파라미터를 받을 수 있습니다.
`flatten`은 어절단위로 배열을 풀어서 1차원으로 만듭니다.
`join`은 출력형식을 "문자열/태그" 바꿔줍니다. full은 숨겨진 정보들도 모두 보여줍니다.
가본값은 `flatten`은 `True`이고, `join`은 `False`, `full`도 `False`입니다. 먼저 `flatten` 값을 `False`로 넘겨보도록 하죠.
`join`도 `True`를 넘겨보겠습니다.

```python
from deeqnlpy import Tagger
t = Tagger()
# 이번에는 문장의 끝에 [요]를 덧붙였습니다.
pos_tuples = t.pos("그 가수는 밍기뉸데요.", flatten=False, join=True)
print(*pos_tuples, sep="\n") 
```

결과물이 조금 바뀌었습니다.
```
>>> print(*aa, sep="\n")
['그/MMD']
['가수/NNG', '는/JX']
['밍기뉴/NNP', '이/VCP', 'ㄴ데/EC', '요/JX', './SF']
```

`flatten`값으로 False를 주자 어절 단위로 쪼개주고, 모두 3개의 배열로 나뉘어진 결과물을 얻을 수 있습니다.
"무리뉸데요."의 경계를 확인하기 쉽지 않았을 텐데, 모두 5개로 쪼개진 것을 알 수 있습니다.
> *<i class="fa fa-info-circle" aria-hidden="true"></i> NNP:*
>     무리뉴는 고유명사입니다. 밍기뉴라는 노래하는 팀 이름이니까요. 근데, 어떻게 알았을까요?

> *<i class="fa fa-info-circle" aria-hidden="true"></i> VCP:*
>    `이`는 생략된 것인데, 복원을 해주었습니다. 이런 형태를 지정사라고 합니다. 서술격조사라고도 했습니다.
> 쉽게 생각하면 명사 다음에 바로 어미가 올 수 없으니까, 어미가 올 수 있도록 어간화 해주는 것으로 이해하면 좋겠습니다.
> 근데 모음으로 끝나는 체언이나 부사 뒤에서 `이`가 생략될 수 있습니다. 구어에서는 흔하게 일어나는 일입니다.

> *<i class="fa fa-info-circle" aria-hidden="true"></i> EF:*
>   종결어미입니다. `ㄴ데`로 문장이 끝나고 있습니다.

> *<i class="fa fa-info-circle" aria-hidden="true"></i> JX:*
>    보조사입니다. 종결어미로 `ㄴ데`로도 충분히 의미를 전달할 수 있는데, `-요`가 붙어서 존대의 뜻을 나타냅니다.

#### 실재로 분석해보기(III)

마지막으로 `full`을 한번 써보도록 할까요?

```python
from deeqnlpy import Tagger
t = Tagger()
pos_tuples = t.pos("그 가수는 밍기뉸데요.", flatten=False, full=True, join=True)
print(*pos_tuples, sep="\n") 
```
```
['그/MMD:0.977']
['가수/NNG:0.915', '는/JX:0.950']
['밍기뉴/NNP:0.464#OUT_OF_VOCAB', '이/VCP:0.980', 'ㄴ데/EC:0.408', '요/JX:0.979', './SF:0.974']
```

디큐 NLP는 조금 더 많은 정보를 보여줍니다. 0.980 이 숫자는 확신을 나타내는 숫자입니다. 딥러닝을 기반으로 하는 디큐NLP에서 스스로 확신하는 정도를 숫자로 나타냅니다. 높으면 높을 수록 개엲성이 높습니다.

> 밍기뉴에는 좀 특이한 `OUT_OF_VOCAB` 이라는 표시가 붙어 있습니다.
>  "밍기뉴"라는 단어는 공부한 단어가 아니라는 뜻입니다.
> 즉, 공부하지 않은 단어 "밍기뉴"를  "NNP" 즉 고유명사로 미뤄 집작하기는 하는데, 조금 조심스럽습니다.
> `0.464` 정도의 확신을 가지고 있을 뿐입니다.
> `OUT_OF_VOCAB` 이런 표시가 없으면 공부한 범위라는 뜻 입니다.
> 대략 디큐 NLP는 20만 단어를 공부하고, 그중에서 9만 단어 정도만 기억하고 있습니다.


#### 실재로 분석해보기(III)

나머지 함수들, morphs(), nouns(), verbs()는 예상한 것과 다르지 않습니다.
앞서 함수의 이름과 기능을 설명했으니, 결과를 직접 눈으로 확인해볼까요?

```python
>>> print(t.morphs("그 가수는 밍기뉸데요."))
['그', '가수', '는', '밍기뉴', '이', 'ㄴ데', '요', '.']
>>> print(t.nouns("그 가수는 밍기뉸데요."))
['가수', '밍기뉴']
>>> print(t.verbs("그 가수는 밍기뉸데요."))
[]
```

### 분석 결과를 재활용하기

지금 호출한 예제를 보면, "그 가수는 밍기뉸데요." 라는 문장을 매번 함수의 첫번째 인자로 넘겨주었습니다.
(1) 형태소를 분석할 때도, (2) 형태소만 분리할 때도, (3) 명사를 구할 때도, (4) 동사를 구할 때도 늘 같은 문장을 넘겨주었습니다. 

조금만 더 깊게 들어가보면, 동일한 문자을 줄 때 나올 결과물은 늘 같은 것입니다.
같아야 합니다.
그러면, 형태소 분석을 한 결과 안에서 형태소 출력을 다양하게 하거나, 명사를 구할 방법은 없을까요.
매번 문장을 인자로 넘겨서 함수를 호출하지 않고 한번만 쓸 수는 없을까요?

바로 이런 목적으로 만들어진 것이 `Tagged` 클래스입니다. 아래 예제에서 `Tagged` 클래스를 사용합니다.

```python
from deeqnlpy import Tagger
t = Tagger()

# 형태소 분석을 한 결과를 tagged 변수로 받습니다.
tagged = t.tag("그 가수는 밍기뉸데요.")
# tagged가 도대체 뭔지 알아봅니다.
help(tagged)
# pos()를 구해봅니다.
tagged.pos()
tagged.pos(join=True, flatten=False)
tagged.pos(join=False, flatten=False, full=True)
# 아까 봤던 nouns(), verbs(), morphs()는 그냥 됩니다.
tagged.nouns()
tagged.verbs()
tagged.morphs()

# 새로운 함수 msg(), 왜 이 함수의 이름은 msg()일까요? 무슨 메시지를 전달하길래..
sents = tagged.msg()
# 아하, json 방식으로 나오는 함수들이 몇가지가 있군요.
json_obj = tagged.as_json()
json_str = tagged.as_json_str()
# 아하, json을 바로 파일로 출력할 수도 있군요.
f = open('out.json', "w+")
tagged.print_as_json(out=f)
close(f)
```

위에서 보면, `tagged` 라는 변수로 받은 `Tagged` 객체에 대해서
`pos()`, `nouns()`, `morphs()`와 같은 메서드는 이미 살펴본 사용법과 같습니다.
새로운 `msg()`, `as_json()`, `print_as_json()`과 같은 메서드들이 추가되어 있는 것을 볼 수 있습니다.
이 메서드는 `Tagged` 클래스에서만 쓸 수 있습니다.

`pos()`, `nouns()`, `morphs()`와 같은 메서드는 오픈소스로 한국어 형태소 분석기를 패키징해 놓은
[KoNLPy](https://pypi.org/project/konlpy/)와 호환성을 유지하기 위해서 만들어진 것입니다.
상용 수준에서 쓰기 위해서 또는 디큐 NLP의 특성을 좀 더 잘 활용하기 위해서 `Tagged` 클래스를 만들었습니다.


#### 약간 다른 방법들

여기에서 pos(), morphs(), nouns(), verbs() 등은 이미 위해서 살펴본 바와 같습니다.
다른 점이 있다면, 매번 호출하는 것이 아나리
이미 호출된 결과물에서 보는 방식만 바꿔보는 것입니다.
침대를 사서 누워도 보고, 배깔고 엎드려도 보고, 걸터 앉아도 보고 다양하게 쓸 수 있으니까요.

#### json으로 출력하는 함수들

```python
tagged.as_json()
```
결과물은 python의 JSON 내장 객체를 사용할 수 있게 해줍니다. 바로 이렇게 생겼습니다.

```python
>>> tagged.print_as_json()
{
  "sentences": [
    {
      "text": {
        "content": "그 가수는 밍기뉸데요."
      },
      "tokens": [
        {
          "text": {
            "content": "그"
          },
          "morphemes": [
            {
              "text": {
                "content": "그"
              },
              "tag": "MMD",
              "probability": 0.9767288
            }
          ],
          "lemma": "그",
          "tagged": "그/MMD"
        },
        {
          "text": {
            "content": "가수는",
            "beginOffset": 2
          },
          "morphemes": [
            {
              "text": {
                "content": "가수",
                "beginOffset": 2
              },
              "tag": "NNG",
              "probability": 0.91464984
            },
            {
              "text": {
                "content": "는",
                "beginOffset": 4
              },
              "tag": "JX",
              "probability": 0.949577
            }
          ],
          "lemma": "가수",
          "tagged": "가수/NNG+는/JX"
        },
        {
          "text": {
            "content": "밍기뉸데요.",
            "beginOffset": 6
          },
          "morphemes": [
            {
              "text": {
                "content": "밍기뉴",
                "beginOffset": 6
              },
              "tag": "NNP",
              "probability": 0.46444348,
              "outOfVocab": "OUT_OF_VOCAB"
            },
            {
              "text": {
                "content": "이",
                "beginOffset": 6
              },
              "tag": "VCP",
              "probability": 0.9800278
            },
            {
              "text": {
                "content": "ㄴ데",
                "beginOffset": 6
              },
              "tag": "EC",
              "probability": 0.40768662
            },
            {
              "text": {
                "content": "요",
                "beginOffset": 6
              },
              "tag": "JX",
              "probability": 0.97902447
            },
            {
              "text": {
                "content": ".",
                "beginOffset": 6
              },
              "tag": "SF",
              "probability": 0.9742079
            }
          ],
          "lemma": "밍기뉴",
          "tagged": "밍기뉴/NNP+이/VCP+ㄴ데/EC+요/JX+./SF"
        }
      ]
    }
  ],
  "language": "ko_KR"
}
>>> 
```

꼼꼼하게 읽어보셨나요?
이제까지 썼던 함수들에 비해서 엄청 복잡한가요?
복잡하지 않습니다. 구조는 단순합니다.


**문장 -> [ 어절 ] -> [ 형태소 ] ->  { 텍스트 조각, 태그, 확률, 미등록단어 정보 }**

정리하면,

- 전체는 여러 문장으로 나뉩니다.
- 한 문장은 여러 여절로 만들어져 있습니다. 어절에는 `lemma`라는 기본형 정보가 있습니다.
- 한 어절은 하나 이상의 형태소로 되어 있습니다. 형태소는 품사 태그와 확신 확률, 미등록 단어 처리 방식 등에 대한 정보가 들어 있습니다.


#### JSON 객체에 접근해보기

```python
# json 객체로 반듭니다.
jo = tagged.as_json()

## 첫번째 문장을 꺼냅니다.
sent1 = jo['sentences'][0]

## 3번째 어절을 찾아갑니다.
token3 = sent1['tokens'][2]

## 각 형태소 객체의 이름과 태그를 출력해봅니다.
for m in token3.morphemes:
    print(m['text']['content'], m['tag'])
```

위와 같이 전통적인 json 객체를 이용해서 쓸 수 있습니다. 파이썬의 JSON 객체는 `dict` 형식을 기본으로하기 때문에 문자열을 키로 움직어야 합니다.
위에서 `sentences`, `tokens`, `text`, `content`, `tag` 등의 문자열이 객체 내부에서 정보를 얻기 위해서 사용된 키입니다.

어떠신가요? 좀 생각보다 쉽습니까? 구조는 여전히 간단합니다.

### msg(), 전정 전하고 싶은 말?

`msg()` 함수는 뭔가 메시지를 전달하고 싶어서 이렇게 이름을 붙이지는 않았습니다.
프로토콜버퍼, `protobuf`라는 기술에서 나온 말입니다. [protobuf](https://developers.google.com/protocol-buffers)는
JSON 포맷으로 표현 가능한 모든 데이터를 표현할 수 있으면서도 네트워크로 전송할 때 크기를 작게 할 수 있습니다.
프로토콜 버퍼에서 가장 작은 데이터 구조의 단위가 `Message` 입니다.

`msg()`라는 함수의 이름은 프로트콜 버퍼의 메시지 형식인 `Message` 객체를 꺼내기 위해서 붙였습니다.
즉, `Tagged` 결과에서 메시지 객체를 꺼내는 작업을 하므로 그렇게 붙인 것입니다.

구조는 위의 `as_json()` 함수를 실행한 결과 만들어진 JSON 객체와 동일합니다.

그 최상위에 문장(sentences)이 있고, 어절(tokens)이 있고, 다시 형태(morphemes) 분석단위가 있습니다.

프로토콜 버퍼의 메시지(Message) 객체로 꺼내온 경우에는 문자열을 키로 사용하지 않고,
변수를 바로 사용할 수 있습니다. 아래와 같이 바로 변수명을 쓸 수 있습니다. 엄청난 차이입니다.
바로 이런 처리를 해주는 기술이 프로토콜 버퍼라고 이해해도 좋습니다.

```python
m = tagged.msg()
print(len(m.sentences[0].tokens))
```
 
이 방식은 JSON를 다루는 방식보다는 훨씬 더 가독성이 좋고, 오류를 일으킬 가능성도 낮습니다.

여기에 쓸 수 있는 변수 및 타입을 모두 정리하였습니다.

#### Sentences

| 속성 | 타입 | 설명 |
|--|--|--|
|sentences| 배열 | `sentencs[0]`과 같은 방법으로 sentencs에 접근 |

#### TextSpan

| 속성 | 타입 | 설명 |
|---|---|---|
|content| string | 텍스트 조각 문자열 |
|begin_offset| integer  | 원 요청 문장에서의 위치, 이것은 요청이 UTF8, UTF16, UTF32이냐에 따라 다릅니다. python3는 내부적으로 UTF32 인코딩을 사용합니다. 결과적으로 유니코드 문자열과 동일합니다. |

#### Sentence

문장 타입입니다.

| 속성 | 타입 | 설명 |
|---|---|---|
| text| 텍스트 조각 객체 | 텍스트 조각 객체 |
| text.content| string | 문장 문자열 |
| text.begin_offset| integer |문장의 시작 위치 |
| tokens | token 객체의 배열 | 어절의 배열 |
| tokens[0] | token 객체 | 문장을 하나 이상의 어절로 분리함 |


#### Token

어절 타입입니다.

| 속성 | 타입 | 설명 |
|----|----|---|
| text | TextSpan 객체 | 토큰 분리에 대한 시작 |
| text.content | string | 토큰 내용 |
| text.begin_offset | integer | 토큰의 시작 위치|
| lemma | string | 원형 |
| tagged | string | 태깅 형태로 만든 문자열, 향후 폐기될 예정입니다. |
| morphemes | 형태소 배열 |  |
| morphemes[0] | 행태소(Morpheme) 객체 | 형태소 객체 |

#### Morpheme

형태소 타입입니다.

| 속성 | 타입 | 설명 |
|----|---|---|
| text | TextSpan 객체 | 형태소 텍스트 조각 |
| text.content | string  | 형태소 내용 |
| text.begin_offset | integer | 형태소 시작 위치 |
| tag | enum | 형태소 내용, 모두 47개의 품사가 사용됩니다. 품사표는 아래를 참조하세요.|
| probability | float | 형태 분류의 정확도 |
| out_of_vocab | enum | 형태 분류 중 사전 활용의 결과 표시. <br> IN_WORD_EMBEDDING: 워드임베딩에 포함된 내용 <br> OUT_OF_VOCAB: 자동 추측 <br> IN_CUSTOM_DICT: 사용자 제공 사전에 있는 내용 <br> IN_BUILTIN_DICT : 기본 사전에 포함된 내용


#### Tag (enum)

[국립국어원](https://www.korean.go.kr/)은 2019년 [모두의 말뭉치](https://corpus.korean.go.kr/#down)에서 새로운 형태소 태깅 규칙을 정의하였습니다.
디큐 NLP는 그 태깅 셋을 사용하여 동작합니다.

아래 표에서 내부인덱스가 사용될 수도 있습니다. `msg()`에서 받은 객체를 json으로 변환할 때, 아래의 enum 이름으로 출력하는 것이 기본이지만, 경우에 따라서 숫자로 나타낼 수도 있습니다. 숫자는 참고하시면 됩니다.

|  이름  | 내부인덱스 |  설명   |
|----|:-:|---|
| NNG|24|일반 명사|
| NNP|25|고유 명사|
| NNB|23|의존 명사|
| NP|26|대명사|
| NR|27|수사|
| NF|22|명사 추정 범주|
| NA|21|분석불능범주|
| NV|28|용언 추정 범주|
| VV|41|동사|
| VA|38|형용사|
| VX|42|보조 용언|
| VCP|40|긍정 지정사|
| VCN|39|부정 지정사|
| MMA|18|성상 관형사|
| MMD|19|지시 관형사|
| MMN|20|수 관형사|
| MAG|16|일반 부사|
| MAJ|17|접속 부사|
| IC|6|감탄사|
| JKS|13|주격 조사|
| JKC|9|보격 조사|
| JKG|10|관형격 조사|
| JKO|11|목적격 조사|
| JKB|8|부사격 조사|
| JKV|14|호격 조사|
| JKQ|12|인용격 조사|
| JX|15|보조사|
| JC|7|접속 조사|
| EP|3|선어말 어미|
| EF|2|종결 어미|
| EC|1|연결 어미|
| ETN|5|명사형 전성 어미|
| ETM|4|관형형 전성 어미|
| XPN|43|체언 접두사|
| XSN|46|명사 파생 접미사|
| XSV|47|동사 파생 접미사|
| XSA|45|형용사 파생 접미사|
| XR|44|어근|
| SF|30|마침표,물음표,느낌표|
| SP|35|쉼표,가운뎃점,콜론,빗금|
| SS|36|따옴표,괄호표,줄표|
| SE|29|줄임표|
| SO|34|붙임표(물결,숨김,빠짐)|
| SW|37|기타기호 (논리수학기호,화폐기호)|
| SL|32|외국어|
| SH|31|한자|
| SN|33|숫자|


#### OutOfVocab (enum)

디큐 NLP는 형태소 태깅을 할 때, 특정 단어를 식별하는 방법을 표시해줍니다. 사용자 사전을 만들 때, 유용하게 쓸 수 있습니다.
프로토콜버퍼는 데이터를 전송할 때, 기본값은 전송하지 않습니다.
`out_of_vocab` 값이 표시되지 않으면 `0`, 즉 `IN_WORD_EMBEDDING` 값이 사용된 것입니다.
명사 및 일부 동사, 형용사를 제외하고는 대부분 다 여기에 속합니다.

|  이름  | 내부인덱스 |  설명   |
|----|:-:|---|
| IN_WORD_EMBEDDING|0| 워드임베딩에 포함된 내용 |
| OUT_OF_VOCAB|1|자동 추측 |
| IN_CUSTOM_DICT|2|사용자 제공 사전에 있는 내용 |
| IN_BUILTIN_DICT|3|기본 사전에 포함된 내용 |


### konlpy에서 deeqnlpy로 바꾸기

기존에 한국어 NLP, 형태 분헉도구를 몇 가지가 있습니다. 가장 널리 쓰이는 것이 Mecab입니다.
기존에 이미 Mecab을 쓰고 계신 분들의 경우, 기존 코드를 조금만 고쳐도 디큐 NLP로 옮겨올 수 있습니다.

매우 간단합니다.

#### 패키지명만 바꾸기

```python
from konlpy.tag import Mecab

tagger = Mecab()
tagger.pos('그 가수는 밍기뉸데요!')
```

이전 코드가 이와 같이 되어 있을 때, 아래와 같이 바꾸면 됩니다.

```python
from deeqnlpy import Tagger

tagger = Tagger()
tagger.pos('그 가수는 밍기뉸데요!')
```

#### Tagged 클래스를 이용해보기

`tag()` 함수를 이용해서 처리하는 것이 조금 더 좋은 방법입니다.
일단 tag 함수를 쓰기 시작하면 다른 메서드들도 슬슬 써볼 수 있을 것입니다.

```python
from deeqnlpy import Tagger

tagger = Tagger()
tagger.tag('그 가수는 밍기뉸데요!').pos()
```

## 마치며

새로운 또 다른 형태소 분석엔진은 아닙니다.
인공지능 시대에 구어를 잘 다루는 엔진이 핵심적으로 중요합니다.

다음 기회에 왜 디큐NLP가 다른지를 설명하도록 하겠습니다.

[deeqnlpy의 소스](https://github.com/baikalai/deeqnlpy)는 깃헙에 공개되어 있습니다.


[wsl2-install]: https://www.44bits.io/ko/post/wsl2-install-and-basic-usage
